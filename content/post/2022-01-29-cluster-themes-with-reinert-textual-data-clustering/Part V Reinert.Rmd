---
title: Part V - Cluster Themes with Reinert Textual Data Clustering
author: Rees Morrison
date: '2022-01-29'
slug: []
categories:
  - Analysis
tags: ["Reinert Textual Data Clustering"]
draft: yes
---

```{r packages, echo=F, warning=FALSE, message=FALSE, include=FALSE, results='hide'}

knitr::opts_chunk$set(echo = FALSE, message = FALSE, warning = FALSE)

library(tidyverse)  
library(ggthemes) 
library(ggrepel) 
library(readxl) 
library(GGally)
library(tidytext) 

library(blogdown)
 
library(rainette)  # had problem installing faststack
library(cluster) # clustering algorithms and gap statistic
library(factoextra) # distance matrix and plot k-means clusters

library(kableExtra)

```


```{r means1, eval=TRUE, warning=FALSE, echo=FALSE}

comboData <- read_xlsx(path = "C:/Users/Rees Morrison/Documents/R/Projects/CLIENTS/Themes/Analytics/comboData.xlsx")

# convert Theme to factor - why?  to try to add labels to corr matrix
comboData$Theme <- as.factor(comboData$Theme)

comboDataMtx <- as.matrix(comboData)  # all numeric, row names 1 to 20

```

```{r normalize1}
comboScaled <- scale(x = comboData[ , 2:20], center = TRUE, scale = TRUE)

comboScaledDF <- as.data.frame(scale(x = comboData[ , 2:20]))
comboScaledDF$Metric <- comboData[  , 1]

```

Concluding this fifth post in my notes on centrality and complexity, the Reinert textual clustering method dates to Max Reinert's articles in 1983. After removing portions of blog posts that are similar to all posts, as well as blogdown header material, I combined all the posts for a Theme into a single "text."  Then I used R's rainette package to perform a Reinert textual clustering on those 24 texts.  Here are some characteristics of the method:

* it assigns each text (Theme) to only one cluster  
* it is better suited for small “homogeneous” documents
* it uses a *singular value decomposition* (SVD) of a *document-term matrix* (DTM) created from the corpus of all texts [more on those two methods in later posts]

The Reinert algorithm carries out <span style="text-decoration: underline">divisive</span> hierarchical clustering with the goal to maximise the inter-cluster <u> Chi-squared distance <\u> between clustered texts.  The algorithm is applied to the DTM, which only stores the presence or absence of terms, not their frequencies. 

The algorithm splits the DTM into two clusters by maximizing the **Chi-squared distance** between them. It carries out the following steps:

* first, texts (Themes) are ordered according to their coordinates on the first axis of the **correspondence analysis** (CA) of the binary matrix (see[DisplayR](https://www.displayr.com/how-correspondence-analysis-works/) for a clear explanation of CA;
    
* next, Themes are grouped in two clusters based on this order, and the grouping with the maximum inter-cluster **Chi-squared distance** is kept;

* based on this grouping, each Theme is in turn assigned to the other cluster. If this new assignment gives a higher inter-cluster Chi-squared value, the Theme is kept in the other cluster. The operation is repeated until no new assignment gives a higher Chi-squared value;
    
* on the resulting clusters' binary matrices, features are selected based on their frequency and on a contingency coefficient minimum value; and
    
* the largest of the two resulting clusters is then split with the same algorithm.

```{r rainette, message=FALSE, echo=FALSE, warnings=FALSE}
# read tidytext file, postWords, created in Themes/BlogNLPWriting.Rmd, with results saved in Themes as .xlsx.  I created PostCombo and then did tidytext to break out all the words

postWords <- readxl::read_xlsx(path = "C:/Users/Rees Morrison/Documents/R/Projects/CLIENTS/Themes/postWords.xlsx")

rainDFM <- postWords %>% group_by(Theme, word) %>% summarise(count = n()) %>% 
  tidytext::cast_dfm(., document = Theme, term = word, value = count)

library(rainette)
# rainClus <- rainette(rainDFM, k = 5, min_segment_size = 5, doc_id = "Theme")
rainClus <- rainette::rainette(rainDFM, k = 18, doc_id = "Theme")

rainCut <- cutree_rainette(hres = rainClus, k = 9)

library(quanteda)
library(quanteda.textstats)
rainStats <- rainette_stats(groups = rainCut, dtm = rainDFM, measure = c("chi2"), n_terms = 10, show_negative = TRUE, max_p = 0.05)

rainDF <- data.frame(C1 = rainStats[[1]][1:2], C2 = rainStats[[2]][1:2], C3 = rainStats[[3]][1:2], C4 = rainStats[[4]][1:2], C5 = rainStats[[5]][1:2], C6 = rainStats[[6]][1:2], C7 = rainStats[[7]][1:2], C8 = rainStats[[8]][1:2], C9 = rainStats[[9]][1:2])

colnames(rainDF) <- str_remove_all(string = colnames(rainDF), pattern = "\\.feature")
colnames(rainDF) <- str_remove_all(string = colnames(rainDF), pattern = "\\.chi2")

rainette_plot(res = rainClus, dtm = rainDFM, k = 9, type = "bar", n_terms = 10, free_scales = TRUE, measure = "chi2", show_negative = "FALSE", text_size = 12)

# rainette2_plot(res = rainClus, dtm = rainDFM, k = 0, type = "bar", n_terms = 10, free_scales = TRUE, measure = "chi2", show_negative = "FALSE", text_size = 12)
```

### Combine the pairings from the three clustering methods

Once the closest-pair are produced from k-means clustering, agglomerative hierarchical clustering, and Reinert text clustering, I combined them into a dataframe so that we can find out whether any Theme is closest to any other Theme more than once (or even three times).\

```{r cluscombo, message=FALSE, echo=FALSE, warnings=FALSE}

##  COMBINE THE CLUSTER RESULTS OF CLOSEST THEMES FROM KMEANS, HIERARCH AND RAINETTE

ThemeLookup <- read_xlsx("C:/Users/Rees Morrison/Documents/R/Projects/CLIENTS/Themes/Metrics of Themes.xlsx", sheet = "NoSThemes", range = "B1:D25")

RainLookup <- data.frame(ClusterGroup = rainClus$group) %>% 
  mutate(Alpha = seq(1:length(ClusterGroup))) %>% 
  left_join(., ThemeLookup[  , c(1, 3)])

RainClosest <- RainLookup %>% group_by(ClusterGroup) %>% summarise(closeThemes = paste0(Theme, collapse = "&")) 

ClusCombo <- as.data.frame(str_split(string = RainClosest$closeThemes, pattern = "&", simplify = TRUE))
colnames(ClusCombo) <- c("Theme1", "Theme2", "Theme3", "Theme4")

ClusCombo$Method <- "Rainette"

```  


```{r combineClosest}
ClusTable <- read_xlsx(path = "C:/Users/Rees Morrison/Documents/R/Projects/CLIENTS/Themes/Analytics/ClusCount.xlsx")

ClusTable <- ClusTable[1:13, 10:14]
colnames(ClusTable) <- c("Theme", "Two", "One", "Theme", "One")

options(knitr.kable.NA = '') # remove NA in cells
kableExtra::kable(ClusTable, caption = 'Close Themes', align = "l",) %>% 
  kable_styling(latex_options = "HOLD_position")
```


## Upcoming Post Series

Once the blog Themes from Art reaches 30 Themes (early February 2022), incorporates new metrics (e.g., newspaper references and Bing searches), drops the most dubious metrics (college majors and readability), and reconsiders the rank metrics (OED Bands and Top 1000 Words), the second series of five posts is likely to address:

*Part VI: Further Observations on Themes and Metrics

*Part VII: Cosine Similarity of Themes

*Part VIII: Latent Dirichelet Allocation (LDA)

*Part IX: Embeddings and Transformations

*Part X: Including Results of Above Algorithms into Theme Pairs Analysis

&nbsp;

Around April 2022, a third series of five posts may encompass 36 Themes, a further modified set of metrics, and the following topics:

*Part XI: Critique of Quantifying Centrality and Complexity

*Part XII: Principal Components Analysis (PCA)

*Part XIII: Latent Semantic Analysis (LSA) or Uniform Manifold Approximation of Proportion (UMAP)

*Part XIV: Correspondence Analysis (CA)

*Part XV: Further Extensions of Theme Pairs and Analysis

&nbsp;

A fourth series of posts, in the early Summer of 2022, may incorporate as many as 40 Themes.  Among its potential topics, we envision:

*Part XVI: More Clustering Techniques

*Part XVII: Metaclustering, Validation tests, Assumptions of the Models

*Part XVIII: Structural Topic Models (STM)

*Part XIX: Other Tools for Analyzing Relationships between Themes

*Part XX: Applications of Theme-Pair Findings to Centrality and Complexity

