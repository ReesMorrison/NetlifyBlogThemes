---
title: Part IV -- Find Similar Themes with Agglomerative Hierarchical Clustering
author: Rees W. Morrison
date: '2022-02-04'
categories:
  - Analysis
tags: 
  - Hierarchical Clustering
output:
  html_document:
    df_print: paged
draft: no
---



<p><a href="https://themesfromart.com/post/2022-02-04-part-1-concepts-quantitatively-compared-and-explored/part-i-themes/">Part I</a> of this working series introduced Themes, and <a href="https://themesfromart.com/post/2022-01-26-part-ii-metrics-that-suggest-centrality-or-complexity-of-a-concept/partiimetrics/">Part II</a> introduced certain metrics pertaining to those Themes. <a href="https://themesfromart.com/post/2022-02-04-part-iii-find-similar-themes-with-k-means-clustering/part-iii-kmeans/">Part III</a> started the analysis of Theme centrality and complexity by an unsupervised clustering algorithm, k-means clustering. It requires the analyst to specify the number of clusters, and figuring out the optimal number of clusters can often be hard. Part III side-stepped that challenge because the k-means algorithm produces data that allows you to calculate the Euclidean distance between closest, most-similar Themes. In this post we introduce a second algorithm for the same task. <strong>Agglomerative hierarchical clustering</strong> is an alternative unsupervised approach; it builds a hierarchy of closest Themes and in doing so creates data that reflects closeness of Themes. That orderly construction of clustering helps identify most-similar Themes, referred to as “closest pairs.”</p>
<p>The hierarchical algorithm starts by putting each Theme in its own unit. It then identifies the closest other Theme by the Euclidean distance between them in a <strong>hyperspace</strong> of 20 dimensions (each Theme is point in that space as determined by the vector of its metrics). At first, a single Theme is clumped with another single Theme, if they are closest to each other, each clumping thereby creating a two-Theme unit as a combined point in hyperspace. Step-by-step the algorithm agglomerates each remaining Theme (or unit) to its closest Theme or unit (based on the chosen <strong>link method</strong>, where we used average linkage); if an already-agglomerated cluster is closest, it clusters the nearest Theme with that unit. Eventually, all the Themes end up in a single cluster.</p>
<p>Once the clustering ends, the results are usually visualized by a <strong>dendrogram</strong>. On the dendrogram, you can tell that two Themes are most similar because they are close on the x axis and the height of the link that joins them together is short. That height on the y-axis is the value of the distance metric between the two Theme points in hyperspace.</p>
<p>In a dendrogram, which subtree should go on the left and which on the right follows the rule that the tighter cluster is on the left (the last, i.e., most recent, merge of the left subtree is at a lower value than the last merge of the right subtree). Merges involving two Themes place them in order by their observation sequence number, which in this instance is the order in which the Themes were first posted on Themes from Art.</p>
<p>Let’s use R’s ggdendro package to visualize the hierarchical clustering results. So, for example, Alcohol and Silence (second and third from the left on the horizontal) are combined to form the first unit. The next-to-last agglomeration, because the vertical distance on the left axis is so large, joins Sports with Work and Time (far right). You can see that Death and Churches are very close, so they cluster very low on the Y axis, and then Trains agglomerates into them.<br />
</p>
<p><img src="/post/2022-02-04-part-iv-cluster-themes-with-agglomerative-hierarchical-clustering/Part%20IV%20Hiearch_files/figure-html/hierarchicalPlotgg-1.png" width="672" /></p>
